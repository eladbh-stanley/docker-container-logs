# Story 1.2 – Gemini Summarisation & Persistence

**Status:** Draft

## Story Statement
As a **developer on-call**, I want each emitted log chunk summarised by Gemini and stored with cost/usage metrics so that I can later review concise TL;DRs and track LLM spend.

## Acceptance Criteria
1. Worker consumes chunks from internal queue (< 100 ms hand-off).
2. Prompt template produces: a) “What happened” (≤ 100 chars); b) key events list; c) open questions.
3. Retry policy: 3 exponential back-offs (1 s → 8 s) on 429/5xx, then mark chunk **failed**.
4. SQLite table `summaries` created with FK to `chunks`; schema matches Architecture doc.
5. Token usage & USD cost persisted per call.
6. Circuit-breaker trips for 5 consecutive failures; health probe shows `summariser_unhealthy`.
7. Prometheus metrics: `gemini_request_seconds_histogram`, `gemini_tokens_total`, `gemini_cost_usd_total`.
8. Integration test stubs Gemini and verifies summary JSON structure + DB insert.

## Dev Notes
* Summariser component: `[Source: architecture/component-descriptions.md#SUM]`
* DB schema reference: `[Source: architecture/persistence-schema-logical.md]`
* Retry & circuit-breaker patterns: `[Source: architecture/security-error-handling.md]`

## Tasks / Subtasks
1. (AC 1) Implement asyncio consumer that reads from chunk queue.
2. (AC 2) Build prompt template & call Gemini SDK; parse structured response.
3. (AC 3, 6) Add retry with back-off and circuit-breaker; expose `/health` flag.
4. (AC 4, 5) Define SQLAlchemy models `Chunk`, `Summary`; migrate DB.
5. (AC 7) Expose Prometheus metrics; add to `/metrics` endpoint.
6. (AC 8) Write integration tests mocking Gemini; assert DB rows & metric increments.

## Project Structure Notes
Creates new package `src/mcp/summariser.py`; models in `src/mcp/models.py` following project conventions.

## Checklist Results
Pending execution of story-draft checklist. 